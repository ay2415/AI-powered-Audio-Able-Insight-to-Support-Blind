# AI-Powered Audio Able Insight for the Visually Impaired

## Overview

This project leverages computer vision and text-to-speech technology to assist visually impaired users by identifying objects in real-time and providing audio feedback about their distance.

## Features

- Real-time object detection using YOLO (You Only Look Once)
- Audio feedback through text-to-speech for detected objects
- Distance estimation based on object size
- Lightweight processing for improved performance

## Requirements

- Python 3.x
- OpenCV
- NumPy
- Pyttsx3
- A YOLO model (weights and configuration files)

## Installation

1. Clone this repository:
   ```bash
   git clone https://github.com/yourusername/repository-name.git
   cd repository-name

2.Install the required packages:
   pip install opencv-python numpy pyttsx3

3.Download the YOLO model files:

YOLOv8 weights
YOLOv8 config
coco.names file

4.Update the file paths in script.py to point to the downloaded YOLO files.

Usage
Ensure your mobile phone camera is accessible over the specified IP address and port.

Run the application:
python script.py



For any questions, feel free to reach out at aashrith2415@gmail.com.


### Notes:
- Replace `yourusername` and `repository-name` with your actual GitHub username and repository name.
- Update the links to the YOLO model files and any other relevant resources as necessary. 

Feel free to copy this content directly into your README.md file!
